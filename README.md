# Big_Data
MapReduce programming model on Hadoop.
Collaborative group project for Big Data Course in University. Goal was to write a MapReduce program identifying users with unique visits based on ip and different minutes online.
Around 12GB of data processed from https://www.sec.gov/dera/data/edgar-log-file-data-set.html distributed on Hadoop on a master-slave architecture.
Executed different testing runs for 1 and 2 nodes and 1,2 and 4 reducers, collected the results and analyzed their running times with graphs. 
